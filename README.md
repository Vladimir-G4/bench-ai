# benchAI

**Benchmark any AI model. With one function.**

benchAI is a plug-and-play evaluation suite for LLM developers. Easily test your prompts across real-world use cases like Q&A, codegen, summarization, and moreâ€”no matter what model you use.

---

## Features

- âœ… **Model-Agnostic** â€” Just pass in a Python function: `Callable[[str], str]`
- ğŸ§  **15+ Built-In Use Cases** â€” Q&A, summarization, codegen, classification, etc.
- ğŸ“Š **Clear Metrics** â€” Exact match, ROUGE, BLEU, syntax checks, and custom validators
- ğŸ”Œ **Adapters for Any Model** â€” OpenAI, HuggingFace, REST APIs, local LLaMA, etc.
- ğŸš€ **CI/CD Ready** â€” Run benchmarks in GitHub Actions for regression tracking
- ğŸ–¥ï¸ **Dual Interface** â€” CLI for devs, UI for PMs and non-tech users

---
